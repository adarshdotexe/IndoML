{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone this repository:\n",
    "!git clone https://github.com/adarshdotexe/IndoML.git\n",
    "%cd /content/IndoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the requirements:\n",
    "%pip install torch transformers datasets sentencepiece rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries:\n",
    "import json\n",
    "import numpy as np\n",
    "from torch import device\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hypothesis-intent mapping:\n",
    "with open('intent_hypothesis_mapping.json') as f:\n",
    "    intent_hypothesis_mapping = json.load(f)\n",
    "\n",
    "\n",
    "# {\"indoml_id\": 1, \"utt\": \"Kindly show me my entire transaction record from the beginning of this year.\"}\n",
    "# {\"indoml_id\": 2, \"utt\": \"Could you help me get this thing delivered today?\"}\n",
    "# {\"indoml_id\": 3, \"utt\": \"Can you join forces with my mobile?\"}\n",
    "data = []\n",
    "with open('massive_test.data') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "premise = [data[i]['utt'] for i in range(len(data))]\n",
    "ids = [data[i]['indoml_id'] for i in range(len(data))]\n",
    "hypothesis = list(intent_hypothesis_mapping.values())\n",
    "\n",
    "# Reverse the mapping:\n",
    "intent_hypothesis_mapping = {v: k for k, v in intent_hypothesis_mapping.items()}\n",
    "\n",
    "\n",
    "\n",
    "# pose sequence as a NLI premise and label as a hypothesis\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "\n",
    "output = []\n",
    "\n",
    "device = device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for p, i in enumerate(premise):\n",
    "    logits = []\n",
    "    for h in hypothesis:\n",
    "        x = tokenizer.encode(p, h, return_tensors='pt',\n",
    "                             truncation_strategy='only_first')\n",
    "        temp_logits = nli_model(x.to(device))[0]\n",
    "        temp_logits = temp_logits[:,[0,2]]\n",
    "        temp_probs = temp_logits.softmax(dim=1)\n",
    "        temp_prob_label_is_true = temp_probs[:,1]\n",
    "        logits.append(temp_prob_label_is_true)\n",
    "    k = np.argmax(logits)\n",
    "    output.append({\"indoml_id\": ids[i], \"intent\": intent_hypothesis_mapping[hypothesis[k]]})\n",
    "\n",
    "with open('massive_test.output', 'w') as f:\n",
    "    for line in output:\n",
    "        f.write(json.dumps(line) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
